{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dr. Sormanni Presentation Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TransformerBeta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide model: total number of parameters: 29437976\n",
      "Wide model: total number of trainable parameters: 29437976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model wide\n",
    "query_size, key_size, value_size, num_hiddens = 512, 512, 512, 512\n",
    "num_layers, dropout = 4, 0.1\n",
    "lr, num_epochs, batch_size, label_smoothing = 0.0004, 500, 6000, 0.1\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 512, 2048, 8\n",
    "\n",
    "norm_shape = [512] # 32 corresponds to the dim of such number to normalize\n",
    "device = d2l.try_gpu()\n",
    "\n",
    "\n",
    "encoder_wide = TransformerEncoder(\n",
    "\tlen(amino_dict), key_size, query_size, value_size, num_hiddens, \n",
    "\tnorm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "\tnum_layers, dropout)\n",
    "decoder_wide = TransformerDecoder(\n",
    "\tlen(amino_dict), key_size, query_size, value_size, num_hiddens, \n",
    "\tnorm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "\tnum_layers, dropout)\n",
    "model_wide = EncoderDecoder(encoder_wide, decoder_wide)\n",
    "\n",
    "\n",
    "model_wide_total_params = sum(p.numel() for p in model_wide.parameters())\n",
    "model_wide_total_trainable_params = sum(p.numel() for p in model_wide.parameters() if p.requires_grad)\n",
    "\n",
    "print('Wide model: total number of parameters: {}'.format(model_wide_total_params))\n",
    "print('Wide model: total number of trainable parameters: {}'.format(model_wide_total_trainable_params))\n",
    "\n",
    "\n",
    "model_wide.load_state_dict(torch.load(\"model_wide_22Jul16_1011AM\", map_location = ('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_beta_strand = 'NRIELKGT' # PDB label = 'VVARTKYK' \n",
    "\n",
    "PNAS_2015_target = 'EQVTNVGG' # paper chosen peptide = 'QYSVLIDA',  paper chosen peptide 2 = 'QYSVLIEF' (alpha-synuclein residues 61-68)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target of selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_target = 'NRIELKGT'\n",
    "model_use = model_wide\n",
    "prediction_length = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional probability at position 1 is 0.9358905553817749\n",
      "Conditional probability at position 2 is 0.8671083450317383\n",
      "Conditional probability at position 3 is 0.7962782979011536\n",
      "Conditional probability at position 4 is 0.922514021396637\n",
      "Conditional probability at position 5 is 0.9255252480506897\n",
      "Conditional probability at position 6 is 0.9258487224578857\n",
      "Conditional probability at position 7 is 0.9241359233856201\n",
      "Conditional probability at position 8 is 0.9532920718193054\n",
      "Conditional probability at position 9 is 0.9239785075187683\n",
      "Input target sequence is NRIELKGT, predicted complementary peptide is VEARTKYK\n",
      "Condition on input, predicted probability is 0.415803644044098\n"
     ]
    }
   ],
   "source": [
    "dec_comple_peptide_pred, dec_prob, dec_attention_weight_seq = predict_greedy_single(model_use, task_target, amino_dict, prediction_length + 2, device, save_attention_weights=True, print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidates sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total candidates sampled: 132\n",
      "number of unique top candidates successfully sampled: 50\n",
      "[['VEARTKYK' '0.4158034920692444']\n",
      " ['VELDGDVK' '0.06144126132130623']\n",
      " ['VVARTKYK' '0.023861050605773926']\n",
      " ['VIARTKYK' '0.0027274086605757475']\n",
      " ['VNARTKYK' '0.0024703301023691893']\n",
      " ['VYARTKYK' '0.0018396908417344093']\n",
      " ['VKARTKYK' '0.0015880581922829151']\n",
      " ['PVARTKYK' '0.001371582387946546']\n",
      " ['VEARTKYN' '0.00130607804749161']\n",
      " ['LVARTKYK' '0.001157547696493566']\n",
      " ['VEARTKTK' '0.0010942153166979551']\n",
      " ['MEARTKYK' '0.001092130201868713']\n",
      " ['VEARTNIS' '0.0010632550111040473']\n",
      " ['VEARTKPV' '0.0010007908567786217']\n",
      " ['VEATTKYK' '0.000990288332104683']\n",
      " ['VEARTKYP' '0.0009733658516779542']\n",
      " ['VEARDKYK' '0.0009230708237737417']\n",
      " ['VEARTWLQ' '0.000921268539968878']\n",
      " ['VEARTKRT' '0.0008684906060807407']\n",
      " ['VELDGDVI' '0.0008510025800205767']\n",
      " ['AVARTKYK' '0.0006835784297436476']\n",
      " ['VEDTMHLD' '0.0006519404123537242']\n",
      " ['YHARTKYK' '0.0005593040841631591']\n",
      " ['VEARSSFT' '0.0005156139959581196']\n",
      " ['HEARTKYK' '0.00039416796062141657']\n",
      " ['WEARTKYK' '0.0003872677043545991']\n",
      " ['VELDGDIK' '0.000282388849882409']\n",
      " ['VEVDGDVT' '0.00018300376541446894']\n",
      " ['VWATLIAI' '0.00018213411385659128']\n",
      " ['WVARTKYK' '0.00012784154387190938']\n",
      " ['VEARTKTG' '7.499902858398855e-05']\n",
      " ['VEAVAALT' '7.1475631557405e-05']\n",
      " ['VEKTLLVT' '6.247923010960221e-05']\n",
      " ['VWATLIGT' '3.2309435482602566e-05']\n",
      " ['VEQTKTFA' '3.0981143936514854e-05']\n",
      " ['VEARTCKT' '1.959903966053389e-05']\n",
      " ['VEWFATVV' '1.1660046766337473e-05']\n",
      " ['VEAFATTG' '1.0917761755990796e-05']\n",
      " ['VECVLEVY' '6.897647381265415e-06']\n",
      " ['VEAQTKLK' '5.848069122293964e-06']\n",
      " ['VMARASFT' '5.248403340374352e-06']\n",
      " ['VMARTKYH' '4.46657440988929e-06']\n",
      " ['VGLTGEGE' '4.458644980331883e-06']\n",
      " ['VQARGDVK' '4.236127551848767e-06']\n",
      " ['VDARTKQK' '3.6947587886970723e-06']\n",
      " ['VVARCVFD' '2.246839812869439e-06']\n",
      " ['VEVAATYT' '6.365760896187567e-07']\n",
      " ['VEAVMLGT' '4.743793056150025e-07']\n",
      " ['YHRTVVEG' '2.9239106424938655e-07']\n",
      " ['VPWTLAVE' '7.069041885188199e-08']]\n"
     ]
    }
   ],
   "source": [
    "num_candidates = 50\n",
    "max_iter = 20\n",
    "\n",
    "peptide_candidates = sample_candidates(model_use, task_target, num_candidates, amino_dict, prediction_length + 2, device, max_iter=max_iter)\n",
    "print(peptide_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peptides pair evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_target = task_target\n",
    "dec_comple_peptide_pred = 'VEAKTKYK'\n",
    "\n",
    "dec_prob, dec_attention_weight_seq = evaluate_single(model_use, task_target, dec_comple_peptide_pred,amino_dict, prediction_length + 2, device, save_attention_weights=True, print_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78bf9874701a3957232b8c741c196d0ac3fa790968bd4270c0e2fd5bdf999274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
