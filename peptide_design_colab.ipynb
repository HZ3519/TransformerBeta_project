{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransformerBeta: An Introduction\n",
    "\n",
    "TransformerBeta is a generative model based on Transformer architecture, developed to generate complementary binder for linear peptide epitopes of length 8 in an antiparallel beta strand conformation. The model is trained on a curated dataset of length 8 antiparallel beta strand pairs from the AF2 Beta Strand Database.\n",
    "\n",
    "![TransformerBeta.png](data:image/png;base64,iVBO)\n",
    "\n",
    "This Google Colaboratory notebook serves as an accessible user interface for TransformerBeta. It allows users to effortlessly generate, predict, and evaluate length 8 antiparallel beta interactions using the TransformerBeta model.\n",
    "\n",
    "For detailed insight into TransformerBeta, we suggest referring to our research paper (yet to be released). \n",
    "\n",
    "To install TransformerBeta locally for your projects, visit: [TransformerBeta on Github](https://github.com/HZ3519/TransformerBeta). \n",
    "\n",
    "For individual usage of the AF2 Beta Strand Database, check out: [AF2 Beta Strand Database on Huggingface](https://huggingface.co/datasets/hz3519/AF2_Beta_Strand_Database/tree/main). \n",
    "\n",
    "For accessing the model weights and corresponding training, validation, and test sets mentioned in the paper, refer to: [TransformerBeta on Huggingface](https://huggingface.co/hz3519/TransformerBeta).\n",
    "\n",
    "## Outline of the Notebook\n",
    "1. Section 1: Setup Guidance\n",
    "2. Section 2: Model Loading\n",
    "3. Section 3: Generation of Peptide Sequences (4 different methods available: 1. Iterative sampling, 2. Random sampling, 3. Greedy prediction, 4. Evaluation of beta conformation probability. Check the cell below for more details.)\n",
    "4. Section 4: Analysis of Iterative Sampling Results (if you choose for this method in Section 3)\n",
    "\n",
    "## Notebook Usage Instructions\n",
    "Please follow the instructions for each section to run the notebook successfully.\n",
    "\n",
    "## Licensing of TransformerBeta\n",
    "\n",
    "TransformerBeta, inclusive of the model weights, training set, validation set, and test set, along with the AF2 Beta Strand Database, is distributed under the terms of the [MIT License](https://opensource.org/licenses/MIT).\n",
    "\n",
    "**Kindly ensure that you adhere to the conditions stipulated by these licenses when using these files.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Setup Guidance\n",
    "\n",
    "Please **strictly follow** the instructions provided in each cell (Go through **Step** in order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setting up Google Drive Connection\n",
    "#@markdown To run TransformerBeta, a connection with your Google Drive is essential. This allows the program to save and access the necessary files.\n",
    "\n",
    "#@markdown **Step 1**: Execute this cell by pressing `Ctrl+Enter` or by clicking the **Play** button to the left.\n",
    "\n",
    "# This chunk will mount Google Drive to allow the storage and retrieval of files\n",
    "from google.colab import drive\n",
    "import os, sys\n",
    "drive.mount('/content/gdrive') # This path is where all output will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Installing Dependencies and TransformerBeta package (this cell takes approx 4mins)\n",
    "#@markdown Ensure your runtime environment is set to CPU. \n",
    "\n",
    "#@markdown **Step 2**: Navigate to `Runtime --> Change runtime type` in the menu above and set the Hardware Accelerator to 'None'.\n",
    "\n",
    "#@markdown **Step 3**: Execute this cell to install the necessary dependencies by pressing `Ctrl+Enter` or by clicking the **Play** button to the left. \n",
    "\n",
    "# remove TransformerBeta_project if it exists\n",
    "import shutil\n",
    "try:\n",
    "  shutil.rmtree('/content/TransformerBeta_project', ignore_errors=True)\n",
    "except:\n",
    "  print('')\n",
    "\n",
    "# personal token for testing repo: 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\n",
    "# if github repo released public\n",
    "# !git clone https://github.com/HZ3519/TransformerBeta_project.git\n",
    "# personal token for testing repo: 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\n",
    "!git clone https://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@github.com/HZ3519/TransformerBeta_project.git\n",
    "\n",
    "!pip install d2l==0.17.5 --no-deps\n",
    "!pip install -r ./TransformerBeta_project/requirements.txt\n",
    "!pip install -e ./TransformerBeta_project\n",
    "\n",
    "import sys\n",
    "if '/content/TransformerBeta_project/' not in sys.path:\n",
    "    sys.path.append('/content/TransformerBeta_project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Restarting Runtime and reconnecting Google Drive\n",
    "#@markdown Once the installation of the necessary packages is completed, a restart of the runtime is required for the changes to take effect.\n",
    "#@markdown **Step 4**: Navigate to `Runtime --> Restart runtime` in the menu above to restart.\n",
    "\n",
    "#@markdown After-restart, the connection to Google Drive needs to be reconnected.\n",
    "#@markdown **Step 5**: Execute this cell again by pressing `Ctrl+Enter` or by clicking the **Play** button to the left to reconnect Google Drive.\n",
    "\n",
    "# reconnect to Google drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown The default model is \"model M retrain\", current best performing model from the paper. Execute this cell by pressing `Ctrl+Enter` or by clicking the **Play** button to the left.\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from TransformerBeta import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "model_name = \"model_M_retrain\" #@param {type:\"string\"}\n",
    "\n",
    "try:\n",
    "  shutil.rmtree('/content/TransformerBeta_models', ignore_errors=True)\n",
    "except:\n",
    "  print('')\n",
    "\n",
    "# git clone the model directory from huggerface\n",
    "!git lfs install\n",
    "# if the hugging face repo is public, change it:\n",
    "# !git clone https://huggingface.co/hz3519/TransformerBeta_models\n",
    "# personal token for testing repo: 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\n",
    "!git clone https://hz3519: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@huggingface.co/hz3519/TransformerBeta_models\n",
    "\n",
    "model_dir = \"TransformerBeta_models/{}\".format(model_name)\n",
    "\n",
    "# Load the config\n",
    "with open(\"{}/config.json\".format(model_dir), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Create instances of your encoder and decoder\n",
    "encoder_standard = TransformerEncoder(\n",
    "    config[\"vocab_size\"], config[\"key_size\"], config[\"query_size\"], config[\"value_size\"], config[\"num_hiddens\"], \n",
    "    config[\"norm_shape\"], config[\"ffn_num_input\"], config[\"ffn_num_hiddens\"], config[\"num_heads\"],\n",
    "    config[\"num_layers\"], config[\"dropout\"])\n",
    "decoder_standard = TransformerDecoder(\n",
    "    config[\"vocab_size\"], config[\"key_size\"], config[\"query_size\"], config[\"value_size\"], config[\"num_hiddens\"], \n",
    "    config[\"norm_shape\"], config[\"ffn_num_input\"], config[\"ffn_num_hiddens\"], config[\"num_heads\"],\n",
    "    config[\"num_layers\"], config[\"dropout\"], shared_embedding=encoder_standard.embedding)\n",
    "\n",
    "# Create an instance of your model\n",
    "model_standard = EncoderDecoder(encoder_standard, decoder_standard)\n",
    "model_standard_total_params = sum(p.numel() for p in model_standard.parameters())\n",
    "model_standard_total_trainable_params = sum(p.numel() for p in model_standard.parameters() if p.requires_grad)\n",
    "\n",
    "# Load the model's state_dict\n",
    "state_dict = torch.load(\"{}/model_weights.pth\".format(model_dir), map_location='cpu')\n",
    "\n",
    "# If the state_dict was saved with 'module' prefix due to DataParallel\n",
    "# Remove 'module' prefix if present\n",
    "if list(state_dict.keys())[0].startswith('module'):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove 'module'\n",
    "        new_state_dict[name] = v\n",
    "    state_dict = new_state_dict\n",
    "    \n",
    "model_standard.load_state_dict(state_dict)\n",
    "\n",
    "model_use = model_standard \n",
    "prediction_length = 8\n",
    "device = d2l.try_gpu()\n",
    "\n",
    "output_dir = \"gdrive/MyDrive/model_prediction_{}\".format(model_name)\n",
    "# save peptide candidates as a txt file in a model prediction folder\n",
    "if not os.path.exists(output_dir):\n",
    "\tos.mkdir(output_dir)\n",
    "\n",
    "print('Transformer model loaded: total number of parameters: {}'.format(model_standard_total_params))\n",
    "print('Transformer model loaded:: total number of trainable parameters: {}'.format(model_standard_total_trainable_params))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Generation of Peptide Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Iterative Sampling\n",
    "\n",
    "#@markdown Iterative sampling samples **num_candidates** non repeative random complementary peptides given a target sequence. \n",
    "\n",
    "#@markdown please specify the length 8 target sequence from N-terminal to C-terminal\n",
    "Target = 'QPRTFLLK' #@param {type:\"string\"}\n",
    "#@markdown specify number of camdidates to sample\n",
    "num_candidates = 50 #@param {type:\"integer\"}\n",
    "#@markdown specify whether to download the sampled candidates files\n",
    "DOWNLOAD = False #@param {type:\"boolean\"}\n",
    "#@markdown After running the code, the results can be accessed either by ticking download file, from your Google Drive or from the left sidebar of this Google Colab notebook at path `gdrive/MyDrive/model_prediction_{model_name}/{Target}_{num_candidates}candidates.txt`\n",
    "\n",
    "#@markdown **Note:** Please only sample 100 candidates maximum at a time in Google Colab. If you want to sample more candidates, please install the project locally and run the code locally with enough memory. Sample time for 100 candidates is ~11 sec.\n",
    "\n",
    "max_iter = 20\n",
    "peptide_candidates = sample_candidates(model_use, Target, num_candidates, amino_dict, prediction_length + 2, device, max_iter=max_iter)\n",
    "# add a reverse column if antiparallel\n",
    "sythesis_pep = np.array([string[::-1] for string in peptide_candidates[:, 0]])\n",
    "peptide_candidates = np.concatenate((peptide_candidates, sythesis_pep.reshape(-1, 1)), axis=1)\n",
    "\n",
    "print('The first 10 examples candidates are:')\n",
    "print('designed complementary peptide, probability, synthesis complementary peptide') \n",
    "print(peptide_candidates[:10])\n",
    "\n",
    "with open('{}/{}_{}candidates.txt'.format(output_dir, Target, num_candidates), 'w') as f:\n",
    "\tfor i in range(len(peptide_candidates)):\n",
    "\t\tf.write(peptide_candidates[i][0] + '\\t' + str(peptide_candidates[i][1]) + '\\t' + str(peptide_candidates[i][2]) + '\\n')\n",
    "\n",
    "if DOWNLOAD:\n",
    "\tfiles.download('{}/{}_{}candidates.txt'.format(output_dir, Target, num_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Random Sampling\n",
    "\n",
    "#@markdown Given a target sequence, random sampling samples 1 random complementary peptide by taking sampling a amino acid at each decoding position.\n",
    "\n",
    "#@markdown please specify the length 8 target sequence from N-terminal to C-terminal\n",
    "Target = 'QPRTFLLK' #@param {type:\"string\"}\n",
    "\n",
    "peptide_candidates = sample_single_candidate(model_use, Target, amino_dict, prediction_length + 2, device)\n",
    "print(peptide_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Greedy Prediction\n",
    "\n",
    "#@markdown Given a target sequence, greedy prediction predicts 1 complementary peptide by taking the amino acid with the highest probability at each decoding position.\n",
    "\n",
    "#@markdown please specify the length 8 target sequence from N-terminal to C-terminal\n",
    "Target = 'QPRTFLLK' #@param {type:\"string\"}\n",
    "\n",
    "dec_comple_peptide_pred, dec_prob, dec_attention_weight_seq = predict_greedy_single(model_use, Target, amino_dict, prediction_length + 2, device, save_attention_weights=True, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Evaluation of beta conformation probability\n",
    "\n",
    "#@markdown Given a target sequence and a complementary peptide, following function evaluates the antiparallel beta conformation probability of the peptide complex.\n",
    "\n",
    "#@markdown please specify the length 8 target sequence from N-terminal to C-terminal\n",
    "Target = 'QPRTFLLK' #@param {type:\"string\"}\n",
    "#@markdown please specify the length 8 complementary peptide from C-terminal to N-terminal (face to face orientation)\n",
    "complementary_peptide = 'LQYDIIFL' #@param {type:\"string\"}\n",
    "\n",
    "dec_prob, dec_attention_weight_seq = evaluate_single(model_use, Target, complementary_peptide, amino_dict, prediction_length + 2, device, save_attention_weights=True, print_info=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Analysis of Iterative Sampling Results (if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load the sampled results\n",
    "\n",
    "#@markdown please specify the length 8 target sequence from N-terminal to C-terminal\n",
    "Target = 'QPRTFLLK' #@param {type:\"string\"}\n",
    "#@markdown specify number of camdidates sampled\n",
    "num_candidates = 50 #@param {type:\"integer\"}\n",
    "#@markdown specify the number of top candidates to analyze\n",
    "num_analysis = 20 #@param {type:\"integer\"}\n",
    "#@markdown specify whether to use training data as a reference\n",
    "use_train = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown If use_train is False, the output table will only contain properties of the analyzed candidates. If use_train is True, the output table will contain properties of the analyzed candidates and their percentile within the training data. For example if hydrophobicity percentile is 90, it means that the hydrophobicity of the candidate is higher than 90% of the training complementary peptides.\n",
    "\n",
    "#@markdown if use_train is False, running time is very short. If use_train is True, analyzing 20 candidates will take ~6mins and running time will increase linearly with the number of analyzed candidates.\n",
    "\n",
    "# read peptide candidates from a txt file in a model prediction folder\n",
    "with open('{}/{}_{}candidates.txt'.format(output_dir, Target, num_candidates), 'r') as f:\n",
    "    peptide_candidates = []\n",
    "    for line in f:\n",
    "        peptide_candidates.append(line.strip().split('\\t'))\n",
    "peptide_candidates_all = np.array(peptide_candidates)\n",
    "\n",
    "# load training data\n",
    "if use_train:\n",
    "\ttrain_dict = np.load('{}/train_data.npy'.format(model_dir), allow_pickle=True)\n",
    "\ttrain_dict = train_dict.tolist()\n",
    "\ttrain_list = []\n",
    "\tfor target, value_dict in train_dict.items():\n",
    "\t\tfor comp, count in value_dict.items():\n",
    "\t\t\ttrain_list.append([target, comp, count])\n",
    "\ttrain_array = np.array(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Analyze the sampled results\n",
    "\n",
    "#@markdown specify whether to download the output table for the sampled candidates\n",
    "DOWNLOAD = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown After running the code, the results can be accessed either by ticking download file, from your Google Drive or from the left sidebar of this Google Colab notebook at path `gdrive/MyDrive/output_analysis_{Target}_{num_candidates}_{num_analysis}.xlsx`\n",
    "\n",
    "# compute the cluster labels\n",
    "cluster_labels_all = compute_clustering_labels(peptide_candidates_all[:, 0], amino_dict)\n",
    "peptide_candidates_analysis = peptide_candidates_all[:num_analysis]\n",
    "cluster_labels_analysis = cluster_labels_all[:num_analysis]\n",
    "\n",
    "# Generate output table for\n",
    "output_file_name = '{}/output_analysis_{}_{}_{}.xlsx'.format(output_dir, Target, num_candidates, num_analysis)\n",
    "peptide_candidates = peptide_candidates_analysis[:, 0]\n",
    "peptide_candidates_prob = peptide_candidates_analysis[:, 1]\n",
    "if use_train:\n",
    "\treference_list = train_array[:, 1]\n",
    "\ttarget_reference_list = train_array[:, 0]\n",
    "else:\n",
    "\treference_list = None\n",
    "\ttarget_reference_list = None\n",
    "generate_output_table(peptide_candidates, peptide_candidates_prob, reference_list, output_file=output_file_name, cluster_labels=cluster_labels_analysis, target=Target, target_reference_list=target_reference_list)\n",
    "\n",
    "if DOWNLOAD:\n",
    "\tfiles.download(output_file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Headers for the output table is defined below:\n",
    "\n",
    "1. **Rank:** The ordinal rank of the peptide candidate ranked by their evaluated probability. The higher rank represents a higher probability of the peptide candidate to be formed in an antiparallel beta conformation.\n",
    "\n",
    "2. **Cluster Label:** The label indicating which cluster the peptide candidate belongs to. It is determined by the K-Medoids algorithm, the number of clusters is set to 2 by default. This label allows users to identify the peptide candidates that are different from each other.\n",
    "\n",
    "3. **Target Sequence:** The target sequence which the complementary peptide is designed for.\n",
    "\n",
    "4. **Designed Complementary Peptide:** The complementary peptide sequences designed by the model. This is designed in an face to face orientation with the target sequence. This means the designed complementary peptide is from C-terminus to N-terminus.\n",
    "\n",
    "5. **Synthesis Complementary Peptide:** The reverse sequence of the designed complementary peptide. This is from N-terminus to C-terminus, which is the order for peptide synthesis in lab.\n",
    "\n",
    "6. **Probability:** The probability score for each peptide candidate evaluted by the model. Higher score indicates a higher probability of the peptide candidate to be formed in an antiparallel beta conformation.\n",
    "\n",
    "7. **Novelty Score:** A score calculated by the closest hamming distance between the designed peptide and all training complementary peptides. Novelty score of 0 indicates the designed peptide is identical to one of the training complementary peptides. Novelty score >= 1 indicates the designed peptide is different from all training complementary peptides. Higher scores suggest higher novelty.\n",
    "\n",
    "8. **Target Novelty Score:** A score calculated by the hamming distance of the Target sequence and the most similar training target sequence of the designed peptide. Target novelty score of 0 indicates the most similar training target sequence of the designed peptide is identical to the target sequence. Target novelty score >= 1 indicates the most similar training target sequence of the designed peptide is different from the target sequence. Higher scores suggest higher novelty.\n",
    "\n",
    "9. **CamSol Solubility Score:** A measure of the peptide's solubility, as calculated by the CamSol method. Higher scores suggest higher solubility. We currently do not have access to the CamSol method, so this column is not available.\n",
    "\n",
    "10. **Net Charge:** The total charge of the peptide, calculated by summing the charge of all amino acids in a peptide.\n",
    "\n",
    "11. **Net Charge Percentile:** The percentile rank of the peptide's net charge compared to the training complementary peptides.\n",
    "\n",
    "12. **Hydrophobicity:** The measure of the peptide's hydrophobicity, calculated by averaging the hydrophobicity (using the Kyte-Doolittle scale) of all amino acids in a peptide.\n",
    "\n",
    "13. **Hydrophobicity Percentile:** The percentile rank of the peptide's hydrophobicity compared to the training complementary peptides.\n",
    "\n",
    "14. **Molecular Weight:** The average molecular weight of the peptide, calculated by averaging the molecular weight of all amino acids in a peptide.\n",
    "\n",
    "15. **Molecular Weight Percentile:** The percentile rank of the peptide's molecular weight compared to the training complementary peptides.\n",
    "\n",
    "16. **Isoelectric Point:** The pH at which the peptide carries no net electrical charge, estimated using Bio.SeqUtils.IsoelectricPoint module in Biopython package. \n",
    "\n",
    "17. **Isoelectric Point Percentile:** The percentile rank of the peptide's isoelectric point compared to the training complementary peptides.\n",
    "\n",
    "18. **Aromaticity:** The percentage of aromatic amino acids in the peptide, calculated by the relative frequency of aromatic amino acids (F, W, Y) in a peptide.\n",
    "\n",
    "19. **Aromaticity Percentile:** The percentile rank of the peptide's aromaticity compared to the training complementary peptides."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
